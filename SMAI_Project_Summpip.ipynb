{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt7jGxd5iE5W",
        "outputId": "6faee235-0c8b-4a5f-a81f-52c46611f6e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# cd drive/MyDrive/SMAI_Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsj6lhHTbXxh"
      },
      "source": [
        "## **IMPORTING LIBRARIES**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPdSNx3diJmR",
        "outputId": "5a9101b3-3d36-4eef-b220-dff8a89a05cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 23:11:08.731428: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-04-19 23:11:08.732687: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-04-19 23:11:08.758935: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-04-19 23:11:08.759532: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-19 23:11:09.378613: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge in ./.venv/lib/python3.10/site-packages (1.0.1)\n",
            "Requirement already satisfied: six in ./.venv/lib/python3.10/site-packages (from rouge) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/siddhant/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import nltk.data\n",
        "import spacy\n",
        "import os\n",
        "import tensorflow_hub as hub\n",
        "import copy\n",
        "!pip install rouge\n",
        "import spacy \n",
        "from tqdm import tqdm\n",
        "from rouge import Rouge\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "use_embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "I_7SiPdSjW3p"
      },
      "outputs": [],
      "source": [
        "src_file = \"./summarizer/DocsData.txt\"\n",
        "tar_file= \"./summarizer/target_new.txt\"\n",
        "k=200"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6_IOXnLbjcy"
      },
      "source": [
        "## **READ DOCUMENTS FROM FILE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EM5xZxprkZya"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[\"GOP Eyes Gains As Voters In 11 States Pick Governors Enlarge this image toggle caption Jim Cole / AP Jim Cole / AP Voters in 11 states will pick their governors tonight , and Republicans appear on track to increase their numbers by at least one , with the potential to extend their hold to more than two - thirds of the nation 's top state offices .\", 'Eight of the gubernatorial seats up for grabs are now held by Democrats ; three are in Republican hands .', \"Republicans currently hold 29 governorships , Democrats have 20 , and Rhode Island 's Gov.\", 'Lincoln Chafee is an Independent .', \"Polls and race analysts suggest that only three of tonight 's contests are considered competitive , all in states where incumbent Democratic governors are n't running again : Montana , New Hampshire and Washington .\", 'While those state races remain too close to call , Republicans are expected to wrest the North Carolina governorship from Democratic control , and to easily win GOP - held seats in Utah , North Dakota and Indiana .', 'Democrats are likely to hold on to their seats in West Virginia and Missouri , and are expected to notch safe wins in races for seats they hold in Vermont and Delaware .', \"Holding Sway On Health Care While the occupant of the governor 's office is historically far less important than the party that controls the state legislature , top state officials in coming years are expected to wield significant influence in at least one major area .\", 'And that \\'s health care , says political scientist Thad Kousser , co - author of The Power of American Governors . \"', \"No matter who wins the  GOP Eyes Gains As Voters In 11 States Pick Governors Jim Cole / AP i Jim Cole / AP Voters in 11 states will pick their governors tonight , and Republicans appear on track to increase their numbers by at least one , and with the potential to extend their hold to more than two - thirds of the nation 's top state offices .\", 'Eight of the gubernatorial seats up for grabs today are now held by Democrats ; three are in Republican hands .', \"Republicans currently hold 29 governorships , Democrats have 20 ; and Rhode Island 's Gov.\", 'Lincoln Chafee is an Independent .', \"Polls and race analysts suggest that only three of tonight 's contests are considered competitive , all in states where incumbent Democratic governors are n't running again : Montana , New Hampshire and Washington .\", 'While those state races remain too close to call , Republicans are expected to wrest the North Carolina governorship from Democratic control , and to easily win GOP - held seats in Utah , North Dakota and Indiana .', 'Democrats are likely hold on to their seats in West Virginia and Missouri ; and expected to notch safe wins in races for seats they hold in Vermont and Delaware .', \"Holding Sway On Health Care While the occupant of the governor 's office is historically far less important than the party that controls the state legislature , top state officials in coming years are expected to wield significant influence in at least one major area .\", 'And that \\'s health care , says political scientist Thad Kousser , co - author of The Power of American Governors . \"', 'No matter who wins the'], ['UPDATE : 4/19/2001 Read Richard Metzger : How I , a married , middle - aged man , became an accidental spokesperson for gay rights overnight on Boing Boing It ’s time to clarify a few details about the controversial “ Hey Facebook what ’s SO wrong with a pic of two men kissing ?', '” story , as it now beginning to be reported in the mainstream media , and not always correctly .', 'First of all , with regards to the picture : The photo which was used to illustrate my first post about the John Snow Kiss - In is a promotional still from the British soap opera “ Eastenders .', '” It features one of the main characters from the show ( Christian Clarke , played by the actor John Partridge- left ) and someone else who I do n’t know .', 'I am not a regular viewer so I ca n’t say if the man on the right is an extra or an actual character .', 'This picture has itself caused scandal in the UK , as it was a gay kiss that was broadcast before the watershed , and as such led to a number of complaints to the BBC .', 'However , since this episode aired ( October 2008 ) Christian now has a boyfriend and a few more gay kisses have taken place .', 'In relation to the John Snow Kiss - In event , I used this particular photo because I considered it to be quite mild ( no groping , no tongues ) .', 'The photos I had considered using before I chose that one are much more racy .', 'Oh the irony !', 'Secondly , the removal of the Facebook John Snow Kiss - In event : It turns out that the Facebook event for the John Snow Kiss - In was not blocked by Facebook , but made private by the creator of the event itself .', 'Paul Shetler , the organizer , left this comment on the previous thread : “ Hey I just saw this .', 'Before it goes too far , I just want people to know that FB have NOT removed the kiss - in event page ; it ’s still there , but _ I made the  || News || Page 1 of 1 UPDATED : A photo of two men kissing that was posted on a Facebook page protesting a London pub ’s decision to eject a same - sex couple for kissing has been removed by the social networking site , an error , according to a rep for the company . \"', 'The photo in question does not violate our Statement of Rights and Responsibilities and was removed in error , \" the statement , obtained by America Blog , says .', 'We apologize for the inconvenience \" The Dangerous Minds Facebook page was set up to promote a “ gay kiss - in ” demonstration in London to protest the pub .', 'The page used a photo of two men kissing to promote the event .', 'According to NYULocal.com , the photo was quickly removed and the following e - mail was sent to administrators of the Facebook page : “ Shares that contain nudity , or any kind of graphic or sexually suggestive content , are not permitted on Facebook .', '” The decision to remove the photo has prompted scores of people to post their own pictures of same - sex couples kissing in protest — dozens in the last few hours alone .']]\n"
          ]
        }
      ],
      "source": [
        "# read source file into a list of list:\n",
        "def read_file(path, file_name, read_lead_only=False, read_first_doc=False):\n",
        "    f = open(os.path.join(path, file_name),\"r\")\n",
        "    lines = f.readlines()\n",
        "    src_list = []\n",
        "    tag=\"story_separator_special_tag\"\n",
        "    for line in lines:\n",
        "        # remove tag; uncomment below for baseline\n",
        "        line = line.replace(tag, \"\")\n",
        "        # tokenzie line to sentences\n",
        "        sent_list = sent_detector.tokenize(line.strip())\n",
        "        src_list.append(sent_list)\n",
        "    return src_list\n",
        "\n",
        "\n",
        "\n",
        "src_list = read_file('', src_file)[:100]\n",
        "with open(tar_file, 'r') as file:\n",
        "    target = file.read().replace('\\n', '')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhYm6eB1nkkj"
      },
      "source": [
        "## **Function to get USE embeddings of the sentences**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXUt7wNbeVfJ"
      },
      "outputs": [],
      "source": [
        "def get_use_embedding(sentence):\n",
        "  embedding = use_embed([sentence]) \n",
        "  embedding = embedding.numpy()\n",
        "  return embedding[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yer3szI5nAjB"
      },
      "source": [
        "## **Functions to compute distance between each pair of sentences**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uS5dCmUBkRxQ"
      },
      "outputs": [],
      "source": [
        "def cosine_dist(A1,B1):\n",
        "  A = np.array(A1)\n",
        "  B = np.array(B1)\n",
        "  mag_A = np.linalg.norm(A)\n",
        "  mag_B = np.linalg.norm(B)\n",
        "\n",
        "  dot_AB = np.dot(A,B)\n",
        "\n",
        "  return (dot_AB)/(mag_A*mag_B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOB2qo7jkRzX"
      },
      "outputs": [],
      "source": [
        "def compute_cosine_mat(em_li, thres):\n",
        "  length = len(em_li)\n",
        "  cos_mat = np.zeros([length, length])\n",
        "  conn_list = []\n",
        "  for i in range(length):\n",
        "\n",
        "    for j in range(i+1,length):\n",
        "\n",
        "      cos_mat[i][j] = cosine_dist(em_li[index_map[i]],em_li[index_map[j]])\n",
        "      cos_mat[j][i] = cos_mat[i][j]\n",
        "      if(cos_mat[i][j]>thres):\n",
        "        # print(i,\" --> \",j)\n",
        "        conn_list.append((index_map[i],index_map[j]))\n",
        "  return cos_mat, conn_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0u1ZnAlZIn2e"
      },
      "outputs": [],
      "source": [
        "def dfs(cur):\n",
        "  if(flag[cur]==1):\n",
        "    return\n",
        "  # print(cur)\n",
        "  flag[cur] = 1\n",
        "  for key in graph_con[cur]:\n",
        "    if(flag[key]==0):\n",
        "      dfs(key)\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8AG9NdFiJtL"
      },
      "outputs": [],
      "source": [
        "# src_file = \"Documents.txt\"\n",
        "# src_list = read_file('', src_file)[:100]\n",
        "\n",
        "# with open(tar_file, 'r') as file:\n",
        "#     target = file.read().replace('\\n', '')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdDowTbMmtwK"
      },
      "source": [
        "## **Based on Cosine Similarity assigning egdes between similar sentences**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tYE_JLqAiJ3t"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'src_list' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m index_map \u001b[39m=\u001b[39m {}     \u001b[39m#  1  -->  1_9  \u001b[39;00m\n\u001b[1;32m      8\u001b[0m inv_index_map \u001b[39m=\u001b[39m {}  \u001b[39m#  1_9 -->  1\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m src_list:\n\u001b[1;32m     10\u001b[0m   s_li \u001b[39m=\u001b[39m []\n\u001b[1;32m     11\u001b[0m   kj\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'src_list' is not defined"
          ]
        }
      ],
      "source": [
        "emb_doc = {}\n",
        "conn_list_All = []\n",
        "N_nodes = 0\n",
        "sen_list=[]\n",
        "ki=0\n",
        "ct=0\n",
        "index_map = {}     #  1  -->  1_9  \n",
        "inv_index_map = {}  #  1_9 -->  1\n",
        "for doc in src_list:\n",
        "  s_li = []\n",
        "  kj=0\n",
        "  for sen in doc:\n",
        "    emb_doc[str(ki)+\"_\"+str(kj)] = get_use_embedding(sen)\n",
        "\n",
        "    index_map[ct] = str(ki)+\"_\"+str(kj)\n",
        "    inv_index_map[str(ki)+\"_\"+str(kj)] = ct\n",
        "    sen_list.append(sen)\n",
        "    kj+=1\n",
        "    ct+=1\n",
        "    N_nodes+=1\n",
        "  ki+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsEzOwI_u_Pu"
      },
      "outputs": [],
      "source": [
        "Ae, c_li = compute_cosine_mat(emb_doc,0.05)\n",
        "graph_con = {}\n",
        "flag = {}\n",
        "for key in inv_index_map:\n",
        "  graph_con[key] = []\n",
        "  flag[key] = 0\n",
        "for tup in c_li:\n",
        "  graph_con[tup[0]].append(tup[1])\n",
        "  graph_con[tup[1]].append(tup[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntLfrAw3mSKz"
      },
      "source": [
        "## **Obtaining the Laplacian Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUOejumgnihE"
      },
      "outputs": [],
      "source": [
        "Are = copy.deepcopy(Ae)\n",
        "for i in range(len(Are)):\n",
        "  for j in range(len(Are[i])):\n",
        "    if(i==j):\n",
        "      Are[i][j] = len(graph_con[index_map[i]])\n",
        "    elif(Are[i][j]>=0.05):\n",
        "      Are[i][j]=-1\n",
        "    else:\n",
        "      Are[i][j]=0\n",
        "# sa=[]\n",
        "# for i in range(0,197):\n",
        "#   sa.append(len(graph_con[index_map[i]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l34kRRzVmZgj"
      },
      "source": [
        "## **Calculating Eigen values & vector**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sV8uXHAw3cxz"
      },
      "outputs": [],
      "source": [
        "Are = Are.astype('int64')\n",
        "w, v = np.linalg.eig(Are)\n",
        "v = np.real_if_close(v, tol=1)\n",
        "w= np.real_if_close(w, tol=1)\n",
        "eigen_asc = []\n",
        "\n",
        "for i in range(len(w)):\n",
        "  eigen_asc.append((w[i],i))\n",
        "eigen_asc.sort(reverse=True)\n",
        "\n",
        "w=np.sort(w)\n",
        "\n",
        "# for i in w:\n",
        "#   print(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6YIFYa4C_83"
      },
      "outputs": [],
      "source": [
        "\n",
        "li_k_vec = []\n",
        "ind_eigv = [] \n",
        "\n",
        "for i in range(k):\n",
        "  ind_eigv.append(eigen_asc[i][1])\n",
        "  li_k_vec.append(v[eigen_asc[i][1]])\n",
        "\n",
        "N_coor = np.array(li_k_vec).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oEPwl9zlJaN"
      },
      "source": [
        "## **Applying K-means Clustering on Embedding obtained above**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOWM1Q8Kjnmt"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=k, n_init=10, random_state=0)\n",
        "kmeans.fit(N_coor)\n",
        "\n",
        "cluster_dict={}\n",
        "for i in range(k):\n",
        "  cluster_dict[i]=[]\n",
        "\n",
        "for i in range(len(sen_list)):\n",
        "  k_num=kmeans.labels_[i]\n",
        "  cluster_dict[k_num].append(sen_list[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlqZS3E6iPyY"
      },
      "outputs": [],
      "source": [
        "# zr=np.zeros(100)\n",
        "# for i in kmeans.labels_:\n",
        "#   zr[i]=zr[i]+1\n",
        "  \n",
        "# for i in zr:\n",
        "#   print(i)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H32hom4lS61"
      },
      "source": [
        "## **POS tagging Senetences to feed it in Compressor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybhCAfdc6o5n"
      },
      "outputs": [],
      "source": [
        "import spacy \n",
        "spacy_=spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def pos_tag(sentences):\n",
        "  out=[]\n",
        "  for sentence in sentences:\n",
        "    sentence =sentence.replace(\"/\",\"\")\n",
        "    word_dict=spacy_(sentence)\n",
        "    temp=[]\n",
        "    for word in word_dict:\n",
        "      tagg=word.text+\"/\"+word.tag_\n",
        "      temp.append(tagg)\n",
        "    out.append(' '.join(temp))\n",
        "  return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4DKzYq5ludk"
      },
      "source": [
        "## **Compressing each cluster**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yw7A8Wjq-1r3"
      },
      "outputs": [],
      "source": [
        "import takahe\n",
        "def compress_cluster(sentences, nb_words):\n",
        "    compresser = takahe.word_graph(sentences, nb_words = nb_words,lang = 'en',punct_tag = \".\" )\n",
        "    candidates = compresser.get_compression(10)\n",
        "    reranker = takahe.keyphrase_reranker(sentences,candidates,lang='en')\n",
        "    reranked_candidates = reranker.rerank_nbest_compressions()\n",
        "    if len(reranked_candidates)>0:\n",
        "        _, path = reranked_candidates[0]\n",
        "        result = ' '.join([u[0] for u in path])\n",
        "    else:\n",
        "        result=' '\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ7m7NTXE5qE",
        "outputId": "aeb2f5a9-cd45-4358-cb4a-e22b22da3d8c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [13:01<00:00,  3.91s/it]\n"
          ]
        }
      ],
      "source": [
        "summary=[]\n",
        "for i in tqdm(range(k)):\n",
        "  summary.append(compress_cluster(pos_tag(cluster_dict[i]),5))\n",
        "ans=\"\".join(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ss3W29yl2_a"
      },
      "source": [
        "## **Comparing obtained summary with target summary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp27lPLK9m9w",
        "outputId": "5d585de3-ce37-4e1a-ffff-592f638e1d35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'rouge-1': {'f': 0.38677861775750105,\n",
              "   'p': 0.6643772893772893,\n",
              "   'r': 0.2727956382778718},\n",
              "  'rouge-2': {'f': 0.11452645722286277,\n",
              "   'p': 0.2662402558464921,\n",
              "   'r': 0.07295432139336182},\n",
              "  'rouge-l': {'f': 0.3545248525968986,\n",
              "   'p': 0.6089743589743589,\n",
              "   'r': 0.25004700131603685}}]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from rouge import Rouge\n",
        "rouge = Rouge()\n",
        "rouge.get_scores(ans,target)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SMAI_Project_Summpip(3)(3).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
